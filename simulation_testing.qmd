---
bibliography: references.bib
---

# Simulation Testing

```{r}
#| message: false
library(tidyverse)
library(gt)
```

## Introduction

Testing a proposed model against simulated data generated from a known underlying process is an important but sometimes overlooked step in ecological research [@austin2006; @lotterhos2022]. In fisheries science, simulation testing is commonly used to evaluate stock assessment and population dynamic models and assess their robustness to various types of error [@deroba2015; @piner2011].

Before applying the size-at-maturity estimation procedures identified through the systematic review to real data, I will create multiple simulated data sets with differing characteristics in order to determine the domains of applicability and inference of each model. The domain of applicability refers to the types of data sets to which a model can reliably be applied, while the domain of inference is defined as the processes or conclusions that can be inferred from the model output [@lotterhos2022]. The methodology for this chapter will be heavily influenced by the principles for ecological simulation testing outlined by Lotterhos et al. [-@lotterhos2022] and the guidelines for computational method benchmarking developed by Weber et al. [-@weber2019] (See [Box 1](#box1)).

::: {#box1 .box}
```{r}

guidelines <- data.frame(
  guide = c(
    "Define the purpose and the scope of the benchmark.",
    "Include all relevant methods.",
    "Select (or design) appropriate datasets.",
    "Choose appropriate parameter values and software versions.",
    "Evaluate methods according to key quantitative performance metrics.",
    "Evaluate secondary metrics including computational requirements, user-friendliness, installation procedures, and documentation quality.",
    "Interpret results and provide recommendations from both user and method developer perspectives.",
    "Publish results in an accessible format.",
    "Design the benchmark to include future extensions.",
    "Follow reproducible research best practices, by making code and data publicly available."
  )
) %>% rownames_to_column("num")


guidelines %>% gt() %>%
  tab_header(title = "Box 1: Computational benchmarking guidelines") %>%
  tab_style(style = cell_borders(sides = c("t"), style = NULL),
            locations = cells_title()) %>% 
  tab_options(column_labels.hidden = TRUE,
              container.padding.y = px(0))

```
:::

## Basic simulation steps

1.  Create normal distribution of crabs with given mean and SD for carapace width
2.  Use logistic distribution function with known location and scale parameters (i.e., known L50 and steepness of the logistic curve) to find the probability of maturity for each individual
3.  Using given parameters for the slope and intercept of the allometric equation, find the predicted chela height for each individual based on their carapace width
4.  Add error representing individual variation in allometric growth, which we assume to be log-normally distributed. Variance in empirical size-at-maturity data often appears higher for mature individuals, so by assuming a multiplicative error structure, these errors will be proportional to the x-axis variable. For example, a measurement error of 4 mm would be less likely to occur when measuring a crab with a carapace that is 30 mm in length (a 13% error) than for a crab with a 100-mm carapace (a 4% error).

## Equations

The parameterization of the logistic equation we will use is: $$f(x)=\frac{1}{1+e^{-(x-a)/b}} $$ where $a$ is a location parameter and $b$ is the shape parameter.

The allometric growth equation is \\begin{equation}\label{eqn:allometry}Y=\\beta X\^{\\alpha},\\end{equation}

which results in a linear plot when log-transformed: $\log{(Y)}= \tilde\beta+\alpha \log{(X)}$. Here, $\alpha$ is the slope of the allometric line and $\beta$ is the intercept, with $\tilde{\beta}=\log{(\beta)}$. Differences in the intercept of the allometry indicate differences in the proportionate size of the chela, irrespective of carapace width. In contrast, differences in the slope parameter represent differences in how the relative size of the chela changes with body size.

## A note on the error distribution

We assume that the errors added in Step 4 are normally distributed around the regression lines obtained by log-transforming the raw CW and CH values. In other words, we are assuming the original data has multiplicative log-normally distributed error:

$$Y=\beta X^{\alpha}e^{\varepsilon}, \quad \varepsilon \sim N(0,\sigma^2)$$ $$\log{(Y)}=\log{(\beta)}+ \alpha\log{(X)}+\varepsilon, \quad \varepsilon \sim N(0,\sigma^2)$$

The question of whether error structures should be assumed to be multiplicative or additive when fitting allometric models is non-trivial and often controversial [@packard2009; @ballantyne2013; @xiao2011]. However, the assumption of multiplicative error is often appropriate for biological contexts and in this case, simulating error based on a multiplicative structure generates artificial data sets that adequately resemble the empirical morphometric data sets we are interested in [@xiao2011; @kerkhoff2009]. Alternative error distributions for allometric models continue to be developed, and future extensions of our research could consider the performance of various size-at-maturity models when applied to simulated data with different forms of error [@echavarría-heras2024].

## Model descriptions

Here will be mathematical descriptions of all of the models I have found so far.

## Testing the models

### Initial comparison - all models

I will first test all methods on “nice” data, which will be 100 randomly generated data sets with the same parametrization, designed to mimic a real-world data set. For the regression methods that accept or require upper and lower bounds for the possible SM50 value, combinations of quantiles representing the upper and lower bounds will be tested, with each combination tested on each of the original 100 randomly generated data sets to determine how slight changes in the data might affect where the upper and lower bounds should be set. For regression methods that accept possible numbers of breakpoints, I will test breakpoint values from 10 to 1000 in increments of 10.

For clustering methods, I will test every combination of distance metric, agglomeration method, or k-means algorithm accepted by the given clustering function. Finally, all of the above procedures will be repeated on log-transformed data, standardized (scaled and centered) data, and, where possible for the method, transformed using PCA.

### Comparison on different data sets

I will choose the best-performing representative (highest % accuracy for clustering methods before regression, lowest MAE) from each general modeling approach to move on to a second round of simulation testing. If not already included, very popular methods (namely, `segmented`, `regrans`, and Somerton’s method) will also be included in the second round of testing. The second round of simulation testing will include changing the location of SM50 within the range of the data, the logistic slope parameter, the allometric growth parameters, and the level of error/noise in the data.

For any remaining regression methods that accept or require upper and lower bounds for the possible SM50 value, I will again test combinations of quartiles representing the upper and lower bounds. This time, the testing will be done for the original parametrization of the data as well as 20 data sets where SM50 is much closer to the low end of the range of x-values and 20 data sets where SM50 is near the higher end of the x values in the data set.

### Testing sampling bias

Simulation studies can serve as a powerful tool to assess the effects of sampling strategies, sample size, and sampling bias on the output of an ecological model [@meynard2019; @lotterhos2022]. For parameter combinations where the model is effective, I will conduct a final round of simulation testing evaluating model performance on different sample sizes and size class representations.

-   100 data sets for each sample size
-   100 data sets for each size class representation (subsample 50-50, subsample 80-20, 20-80)

## References {.unnumbered}
